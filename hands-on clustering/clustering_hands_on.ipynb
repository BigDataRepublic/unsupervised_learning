{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple clustering exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many clusters are in the below graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('dataset_1.csv')\n",
    "plt.scatter(X['0'], X['1'], s=5, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply k-Means to the above dataset. What values do you pick for your parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your choices using the elbow method and the silhouette scores\n",
    "For the silhouette score, there's existing code available on the [sklearn website](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a few other clustering methods. Which ones do you think would work well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a new dataset. Apply the relevant method and evaluate your fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('dataset_2.csv')\n",
    "plt.scatter(X['0'], X['1'], s=5, color='k');\n",
    "\n",
    "# Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're feeling motivated, here's a third dataset.\n",
    "You can find a nice overview of methods here: https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('dataset_3.csv')\n",
    "plt.scatter(X['0'], X['1'], s=5, color='k');\n",
    "\n",
    "# Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical clustering\n",
    "\n",
    "Hierarchical clustering is based on three major steps:\n",
    "1. Finding the similarity or dissimilarity between every pair of objects in the data set.\n",
    "\n",
    "2. Recursively group the objects into a binary, hierarchical tree (dendrogram) with different linkage methods.\n",
    "\n",
    "3. Determine where to cut the tree into clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go back to the first dataset and create a dendrogram. Which linkage metric do you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('dataset_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import (\n",
    "    dendrogram,  # For drawing the dendrogram\n",
    "    linkage,  # For creating the dendrogram.\n",
    ")\n",
    "\n",
    "X = pd.read_csv('dataset_1.csv')\n",
    "\n",
    "# Z = linkage(...)\n",
    "\n",
    "\"\"\"\n",
    "Complete link method\n",
    "This method defines the distance between two groups as the distance between their two farthest-apart members. This method usually yields clusters that are well separated and compact.\n",
    "\n",
    "Average link method\n",
    "This algorithm defines the distance between groups as the average distance between each of the members, weighted so that the two groups have an equal influence on the final result. \n",
    "\n",
    "Single link method\n",
    "The distance between two groups is defined as the distance between their two closest members.\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "dendrogram(Z, leaf_font_size=12)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Customers')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the dendrogram with respect to the distances. \n",
    "\n",
    "- Which linkage works best for separating the clusters?\n",
    "- Could you reconstruct the distances between the data points from the graph?\n",
    "- Based on the graph, how many clusters are present?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To generate a clustering from a dendorgram, the tree has to be cut at a horizontal level. Where do you place the cut?\n",
    "- Also color the points with your respective clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster  # For splitting the dendrogram at a given depth\n",
    "\n",
    "# max_depth = ...\n",
    "\n",
    "labxNew = fcluster(Z, max_d, criterion='distance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have outliers, which linkage type would you select?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative exercise 1: image compression with clustering\n",
    "k-Means can be used to compress images by clustering similar colours and recolouring the image. The resulting image has a comic book-esque appearence.\n",
    "\n",
    "Implement an image compression algorithm using k-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Sample code.\n",
    "# Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creative exercise 2: Feature engineering & dimension reduction with k-Means\n",
    "If you have a supervised learning problem that is difficult and seems non-linear, you can apply clustering methods to create new and non-linear features. \n",
    "\n",
    "Say we cluster a dataset with k-means into 5 clusters. We can now express every data point with its respective distance to each cluster centroid, effectively creating 5 new features. These new features can make non-linear problems linearly separable. \n",
    "\n",
    "**Implement an `sklearn` transformer that creates new features using k-Means.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
